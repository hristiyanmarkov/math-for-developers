{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbebc503",
   "metadata": {},
   "source": [
    "Student: @hristiyanmarkov94\n",
    "\n",
    "Course: Math for Developers 2023 / SoftUni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b73bcda",
   "metadata": {},
   "source": [
    "### 3. Huffman Compression Algorithm\n",
    "Examine and implement the **Huffman algorithm** for compressing data. It's based on information theory and probability theory. Document your findings and provide your implementation.\n",
    "\n",
    "This algorithm is used for **lossless compression**: compressing data without loss of quality. You can use the following checklist:\n",
    "\n",
    "* What is the difference betwenn lossless and lossy compression?\n",
    "* When can we get away with lossy compression?\n",
    "* What is entropy?\n",
    "* How are Huffman trees constructed?\n",
    "    * Provide a few examples\n",
    "* How can we get back the uncompressed data from the Huffman tree?\n",
    "* How and where are Huffman trees stored?\n",
    "* Implement the algorithm. Add any other formulas / assumptions / etc. you might need.\n",
    "* Test the algorithm. A good meaure would be percentage compression: $$\\frac{\\text{compressed}}{\\text{uncompressed}} * 100\\%$$\n",
    "* How well does Huffman's algorithm perform compared to other compression algorithms (e.g. LZ77)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b75b01",
   "metadata": {},
   "source": [
    "### Lossless vs. Lossy Compression\n",
    "\n",
    "Data compression allows us to store information using less storage, i.e. using fewer bits. The algorithms that achieve this can be divided in two - **lossless**, where no information is lost, and **lossy**, where some less important pieces are removed.\n",
    "\n",
    "We can use data compression on pretty much any type of data - text, images, audio, video, but there are of course differences if we want to implement lossy or lossless compression.\n",
    "\n",
    "For example, we cannot afford to lose information from a text file. Be it a whole paragraph or a single comma that the algorithm removes, it might change the intention of the text completely. Because of this, a lossless compression is prefered.\n",
    "When working with images, audio, and video files, we have many different use cases. Are we storing a million images of cats or highly detailed scans of famous paintings? Are we playing a song on the phone, or are we recording a live orchestra? Is the video going to be played on a small 5-inch phone or in an IMAX theater?\n",
    "\n",
    "Depending on the audience, we can afford to lose some quality during playback, in favor of putting more files in the same space. And vice-versa, wherever detail is needed, and we need to be precise, lossless compression is the better route.\n",
    "Of course, different algorithms have different parameters, and are tuned for different uses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f99e9c",
   "metadata": {},
   "source": [
    "### Entropy\n",
    "\n",
    "Entropy is a term and concept using in many fields of science, generally interpreted as to how random (disordered) a system is.\n",
    "\n",
    "In **Information theory**, the *entropy* of a variable is the level of information or uncertainty present of any of the variable's possible outcomes. The *entropy state function* is the amount of information that is needed to fully describe the microstate of the system.\n",
    "\n",
    "The core idea of information theory is that every message has a value, which depends on how \"suprising\" its contents are. If a highly likely event occurs, the message brings us little information. On the other hand, if an unlikely event occurs, our message is much more valuable, and carries more information. A simple example is that a message with the winning lottery numbers contains a lot of information, while a message with non-winning numbers doesn't have much informational value.\n",
    "\n",
    "We can define the *information content* for an event $E$, which increases while its probability $p(E)$ decreases. The function that describes this relationship is $\\log\\left(\\frac{1}{p(E)}\\right)$, where if $p(E)$ is approaching 1, the surprisal of the event is low, but if $p(E)$ is close to 0 the surprisal is high.\n",
    "Furthermore, we can define the information of an event $E$ by $$I(E) = -\\log_2(p(E))$$ or $$I(E) = \\log_2\\left(\\frac{1}{p(E)}\\right)$$\n",
    "\n",
    "Information theory is useful when we're trying to calculate how small we can make a message (compression). Transmitting text containing just 4 equally likely characters over a binary channel can't be optimized, as all 4 will require two bits to be encoded (let's say 'A' = 00, 'B' = 01, 'C' = 10, 'D' = 11). However, if we have unequal probabilities, we can assign different lengths of code to each character so that fewer than 2 bits are sent on average. With 70% chance for 'A', 26% for 'B' and 2% for 'C' and 'D', we can code 'A' = 0, 'B' = 10, C = 110, D = 111. This way, we'll send a single bit 70% of time. It's interesting to note that texts have different entropy based on the language they're written in, for examply English has 9.1 bits of entropy per word, while Finnish 10.4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea7c9e0",
   "metadata": {},
   "source": [
    "### Huffman Coding\n",
    "\n",
    "Huffman Coding is a lossless compression algorithm. It's predominantly used to compress data with frequently occuring characters. It relies on variable-length code and binary trees. The method was first used by David Huffman in 1951, and it's currently used in compression formats like *PKZIP, GZIP*, storage formats like *JPEG, PNG, MP3*, and transmitting text through fax.\n",
    "The algorithm was quickly proven optimal for some cases by its author, but there are instances where it's slow and/or suboptimal:\n",
    "- it's not optimal unless all probabilities for the encoded symbols are in the form of $2^{-n}$\n",
    "- when the input data has many different symbols, decoding (rebuilding the Huffman tree) can be very slow, as there are many nodes to go through\n",
    "\n",
    "\n",
    "### Constructing the Huffman tree\n",
    "\n",
    "To construct a Huffman tree, we need a set of symbols and their frequency (weights) $F$.\n",
    "\n",
    "<img src=\"https://cdn.programiz.com/sites/tutorial2program/files/hf-string.png\" width = 50%>\n",
    "<img src=\"https://cdn.programiz.com/sites/tutorial2program/files/hf-character-frequency.png\" width = 30%>\n",
    "\n",
    "1. We start by ordering the symbols in increasing order their frequency. Store this in a priority queue $Q$.\n",
    "\n",
    "<img src=\"https://cdn.programiz.com/sites/tutorial2program/files/hf-character-frequency-sorted.png\" width = 30%>\n",
    "\n",
    "2. For every unique symbols create a node.\n",
    "3. Create an empty node $Z$, and assign the two least-common symbols under it. Generally the left one is the less common one, and right is the more popular one.\n",
    "\n",
    "<img src=\"https://cdn.programiz.com/sites/tutorial2program/files/hf-encoding-1.png\" width = 30%>\n",
    "\n",
    "4. The value of the newly created node $Z$ is the sum of frequencies of its child nodes.\n",
    "5. Remove the child nodes from $Q$ and add their sum into the list of frequencies $F$.\n",
    "6. Insert the node $Z$ into the tree.\n",
    "7. Repeat 3-5 for all symbols.\n",
    "\n",
    "<img src=\"https://cdn.programiz.com/sites/tutorial2program/files/hf-encoding-2.png\" width = 30%>\n",
    "\n",
    "<img src=\"https://cdn.programiz.com/sites/tutorial2program/files/hf-encoding-3.png\" width = 30%>\n",
    "8. For each connection between nodes, assign 0 to the left edge and 1 to the right edge.\n",
    "\n",
    "<img src=\"https://cdn.programiz.com/sites/tutorial2program/files/hf-encoding-4.png\" width = 30%>\n",
    "\n",
    "\n",
    "### Decoding\n",
    "\n",
    "To find the symbol behind each code, we simply go through the tree in reverse (from top to bottom). \n",
    "\n",
    "<img src=\"https://cdn.programiz.com/sites/tutorial2program/files/hf-decoding.png\" width = 30%>\n",
    "\n",
    "- To see what 101 decodes to, we go from the top node, then right (1), then left (0) and then right (1) again - finishing at 'D'.\n",
    "- If we have a longer code, like 011101, we do the same:\n",
    "    - left (0) - we arrive at 'C', so this must be the first character\n",
    "    - start again from the top of the tree with right (1), right (1) and find 'A' - that's the second character\n",
    "    - start again from the top for right (1), left (0) and right (1) to 'D' - 011101 decodes to 'CAD'\n",
    "    \n",
    "### Efficiency\n",
    "\n",
    "Initially, to store each symbol we needed 8 bits. For our example, this amounts to 120 bits total. Let's see how much space each one needs after the algorithm has been implemented:\n",
    "\n",
    "| Symbol       \t| Frequency \t| Code \t| Size     \t|\n",
    "|-----------------\t|-----------\t|------\t|----------\t|\n",
    "| A               \t| 5         \t| 11   \t| 5x2 = 10 \t|\n",
    "| B               \t| 1         \t| 100  \t| 1x3 = 3  \t|\n",
    "| C               \t| 6         \t| 0    \t| 6x1 = 6  \t|\n",
    "| D               \t| 3         \t| 101  \t| 3x3 = 9  \t|\n",
    "| 4x8 = 32 bits \t| 15 bits   \t|      \t| 28 bits  \t|\n",
    "\n",
    "The average code length is represented as $$\\frac{\\sum(frequency_i \\times codelength_i)}{\\sum(frequency_i)}$$\n",
    "And the total length of an encoded message in bits is the number of characters x average code length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa584af",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb0c5724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from compress import Compressor\n",
    "import lzma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acbc4830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the frequency of each character in the input string and store it in a dictionary\n",
    "def CalculateFrequencies(string):\n",
    "    freq = dict()\n",
    "    for char in string:\n",
    "        if char in freq:\n",
    "            freq[char] += 1\n",
    "        else:\n",
    "            freq[char] = 1\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcd7e364",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t': 3, 'e': 1, 's': 2, 'i': 2, 'n': 2, 'g': 2, ' ': 1, 'r': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_test_string = \"testing string\"\n",
    "CalculateFrequencies(freq_test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df7d5672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'т': 2,\n",
       " 'е': 1,\n",
       " 'к': 2,\n",
       " 'с': 2,\n",
       " ' ': 8,\n",
       " 'н': 1,\n",
       " 'а': 3,\n",
       " 'и': 4,\n",
       " 'р': 1,\n",
       " 'л': 2,\n",
       " 'ц': 1,\n",
       " ',': 1,\n",
       " 'l': 2,\n",
       " 'a': 3,\n",
       " 't': 1,\n",
       " 'i': 1,\n",
       " 'n': 2,\n",
       " 'd': 1,\n",
       " 's': 2,\n",
       " 'o': 2,\n",
       " 'm': 1,\n",
       " 'e': 1,\n",
       " 'ч': 1,\n",
       " '0': 1,\n",
       " '1': 1,\n",
       " '2': 1,\n",
       " '8': 4,\n",
       " '5': 3,\n",
       " '9': 2,\n",
       " '3': 6}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_test_string_2 = \"текст на кирилица, latin and also some числа 012859389583583333\"\n",
    "CalculateFrequencies(freq_test_string_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2db9418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Node\n",
    "# frequency is the frequency of the symbol or the sum of the frequency of the 2 child-nodes\n",
    "# symbol is the symbol to be encoded\n",
    "# left and right are the edges to traverse the tree on, 0 = left, 1 = right\n",
    "class Node:  \n",
    "    def __init__(self, frequency, symbol, leftEdge = None, rightEdge = None):  \n",
    "        self.frequency = frequency  \n",
    "        self.symbol = symbol \n",
    "        self.leftEdge = leftEdge  \n",
    "        self.rightEdge = rightEdge  \n",
    "        self.code = '' # otherwise it doesn't work :) gets the values 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1248a3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t\n",
      "e\n",
      "s\n",
      "_\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n"
     ]
    }
   ],
   "source": [
    "nodes = []\n",
    "symbols = CalculateFrequencies(\"test_string_test\").keys()\n",
    "for s in symbols:\n",
    "    nodes.append(Node(CalculateFrequencies(\"test_string_test\").get(s), s))\n",
    "\n",
    "for i in range(len(nodes)):\n",
    "    print(nodes[i].symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db93ce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the input string\n",
    "def Encode(string):\n",
    "    # check for bad input\n",
    "    if string == '':\n",
    "        raise Exception (\"Can't use an empty string!\")\n",
    "    if type(string) != str:\n",
    "        raise Exception (\"Only strings are allowed!\")\n",
    "    if len(set(string)) == 1:\n",
    "        raise Exception (\"Input has a single distinct symbol, can't encode!\")\n",
    "\n",
    "    # get the frequency map and make two arrays for it\n",
    "    cf = CalculateFrequencies(string)\n",
    "    symbols = cf.keys()\n",
    "    freqs = cf.values()\n",
    "    \n",
    "    #print(\"symbols: \", symbols)  \n",
    "    #print(\"frequencies: \", freqs)  \n",
    "\n",
    "    # this will contain our nodes\n",
    "    nodes = []  \n",
    "      \n",
    "    # let's create nodes for all the symbols at once\n",
    "    for s in symbols:  \n",
    "        nodes.append(Node(cf.get(s), s))  \n",
    "      \n",
    "    while len(nodes) >= 2:  \n",
    "        # sort the nodes in the tree by their frequency\n",
    "        nodes = sorted(nodes, key = lambda x: x.frequency)  \n",
    "        \n",
    "        # uncomment to debug and see the tree as it gets built\n",
    "        #for n in nodes:    \n",
    "            #print(node.symbol, node.frequency)\n",
    "      \n",
    "        # assign values to left and right \n",
    "        right = nodes[0]  \n",
    "        left = nodes[1]  \n",
    "      \n",
    "        left.code = 0  \n",
    "        right.code = 1  \n",
    "      \n",
    "        # build a new node from two child-nodes\n",
    "        newNode = Node(left.frequency + right.frequency, left.symbol + right.symbol, left, right)  \n",
    "        \n",
    "        # now, remove the preexisting nodes, otherwise we get duplications\n",
    "        nodes.remove(left)  \n",
    "        nodes.remove(right)  \n",
    "        nodes.append(newNode)  \n",
    "    \n",
    "    # this dict will store each symbol and its corresponding binary code\n",
    "    code_list = dict()\n",
    "    \n",
    "    huffmanEncoding = GetCodeList(nodes[0], code_list)\n",
    "    \n",
    "    # merge the dictionaries with frequencies and codes\n",
    "    sortedEncode = MergeDicts(cf, huffmanEncoding)\n",
    "    \n",
    "    #print(cf, huffmanEncoding, sortedEncode) \n",
    "    \n",
    "    print(\"{:<8} {:<15} {:<10}\".format('Symbol', 'Code', 'Frequency'))\n",
    "    for k, v in sorted(sortedEncode.items(), key = lambda k: (k[1][0], k[1][1]), reverse = True):\n",
    "        print(\"{:<8} {:<15} {:<10}\".format(k, v[1], v[0]))\n",
    "\n",
    "    #print(\"symbols with codes\", huffmanEncoding)\n",
    "    CalculateEfficiency(string, huffmanEncoding)  \n",
    "    res = EncodedResults(string, huffmanEncoding)  \n",
    "    return res, nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89bf4190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for the output table\n",
    "def MergeDicts(d1, d2):\n",
    "    dd = defaultdict(list)\n",
    "\n",
    "    for d in (d1, d2): # you can list as many input dicts as you want here\n",
    "        for key, value in d.items():\n",
    "            dd[key].append(value)\n",
    "    \n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d92f6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# goes through the tree and returns the code for each symbol\n",
    "def GetCodeList(node, code_list, value = ''):\n",
    "    # a huffman code for current node  \n",
    "    newValue = value + str(node.code)  \n",
    "  \n",
    "    if(node.leftEdge):  \n",
    "        GetCodeList(node.leftEdge, code_list, newValue)  \n",
    "    if(node.rightEdge):  \n",
    "        GetCodeList(node.rightEdge, code_list, newValue)  \n",
    "  \n",
    "    if(not node.leftEdge and not node.rightEdge):  \n",
    "        code_list[node.symbol] = newValue  \n",
    "           \n",
    "    return code_list  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c5bbd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a dict with each symbol's code\n",
    "def EncodedResults(string, coding):  \n",
    "    result = []  \n",
    "    for s in string:  \n",
    "        # print(coding[element], end = '')  \n",
    "        result.append(coding[s])  \n",
    "          \n",
    "    #string = ''.join([str(item) for item in result])\n",
    "    encoded_string = ''\n",
    "    for r in result:\n",
    "        encoded_string += str(r)\n",
    "    return encoded_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de83ccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the effectiveness of the algorithm, before vs. after the compression\n",
    "def CalculateEfficiency(string, coding):  \n",
    "    # total bit space to store the data before compression  \n",
    "    regular = 8 * len(string) # assuming 8 bits per character\n",
    "    compressed = 0\n",
    "    symbs = coding.keys()\n",
    "    for s in symbs:\n",
    "        c = string.count(s)\n",
    "        # calculating how many bits are required for that symbol in total\n",
    "        compressed += c * len(coding[s])\n",
    "    print(\"Compressed size vs. original (bits): \", \"{0:.00%}\".format(compressed/regular), \", \", compressed, \"/\", regular, \" bits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b041f625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the binary code and relevant tree and output the decoded string\n",
    "def Decode(encodedData, tree):\n",
    "    start = tree\n",
    "    result = []\n",
    "    for x in encodedData:\n",
    "        if x is None:\n",
    "            result.append(tree.symbol)\n",
    "            tree = start\n",
    "        elif x == '1':\n",
    "            tree = tree.rightEdge    \n",
    "        elif x == '0':\n",
    "            tree = tree.leftEdge\n",
    "        elif tree.rightEdge.symbol == None and tree.leftEdge.symbol == None:\n",
    "            pass\n",
    "        try:  \n",
    "            if tree.rightEdge.symbol == None and tree.leftEdge.symbol == None:  \n",
    "                pass  \n",
    "        except:\n",
    "            result.append(tree.symbol)  \n",
    "            tree = start  \n",
    "\n",
    "    #string = ''.join([str(item) for item in result])\n",
    "    decoded_string = ''\n",
    "    for r in result:\n",
    "        decoded_string += str(r)\n",
    "    return decoded_string  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a9f4e79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol   Code            Frequency \n",
      "         11              60        \n",
      "e        101             32        \n",
      "t        0010            27        \n",
      "i        0101            20        \n",
      "a        0111            17        \n",
      "l        0110            17        \n",
      "r        1001            16        \n",
      "n        00000           16        \n",
      "h        00010           15        \n",
      "s        01000           11        \n",
      "o        00111           11        \n",
      ".        000010          8         \n",
      "m        000011          7         \n",
      "w        001100          6         \n",
      "I        010010          5         \n",
      "g        001101          5         \n",
      "f        100011          4         \n",
      "d        100010          4         \n",
      "p        100001          4         \n",
      "u        0001111         3         \n",
      "b        0001110         3         \n",
      "y        0001101         3         \n",
      "-        1000001         2         \n",
      "F        00011000        2         \n",
      "k        10000001        1         \n",
      "c        10000000        1         \n",
      "v        01001111        1         \n",
      "A        01001110        1         \n",
      ",        01001101        1         \n",
      "W        01001100        1         \n",
      "O        00011001        1         \n",
      "Compressed size vs. original (bits):  52% ,  1276 / 2440  bits\n",
      "Encoded \n",
      " 0100101100001100011110100000101100000001110010111000111010111100100001011000110001010111100111010101000110010000101011100001101010000010001010000011000000101010110011010110010000101100011000101011110011101010100011001000010101110110010100100010011010110000011000101010111001000010110010000100111001011000111010010101000000011010100011001000111001001110110110011100011100110010100101011001011100100101001110000000001011010010110011000101011001101110001101111000000010111000011000110111100011101011110010000101101001011001100010101100110111000011011001000011010100101101010010110010001111110000101110100001000110011101001111101100111000011101110111000001000101100100001010010011100011110011010001011000011101000010110100111000000100010110011000001010100000110101001011000100111010001100110100111000001011110000101110100000100100110111010010110011000101011001101100100001111100100000110010000101011101010000000000101100111101000110110111001000111110100010110111010100100100011100001011100100001000001011010011000001010110011011100100001010111100011101011110011100010011101000110011010011100000101110010000101011001101110011000101011001101100011101011100000001110010000100101000000011010000101100011001000000110000110111010010110011000101011001101110011010000110111010100000000010\n",
      "Decoded \n",
      " I must not fear. Fear is the mind-killer. Fear is the little-death that brings total obliteration. I will face my fear. I will permit it to pass over me and through me. And when it has gone past, I will turn the inner eye to see its path. Where the fear has gone there will be nothing. Only I will remain.\n"
     ]
    }
   ],
   "source": [
    "test_string = \"I must not fear. Fear is the mind-killer. Fear is the little-death that brings total obliteration. I will face my fear. I will permit it to pass over me and through me. And when it has gone past, I will turn the inner eye to see its path. Where the fear has gone there will be nothing. Only I will remain.\"\n",
    "encoding, tree = Encode(test_string) # we could also use test_string.lower() and increase efficiency a tiny bit  \n",
    "print(\"Encoded \\n\", encoding)\n",
    "print(\"Decoded \\n\", Decode(encoding, tree))\n",
    "assert(Decode(encoding, tree) == test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdb3f0a",
   "metadata": {},
   "source": [
    "### Comparison with other compression algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a51764e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'I must not fear. Fear is the mind-killer. Fear is the little-death that brings total obliteration. I will face my fear. I will permit it to pass over me and through me. And when it has gone past, I will turn the inner eye to see its path. Where the fear has gone there will be nothing. Only I will remain.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare with LZMA\n",
    "binary_data = (test_string).encode(\"utf-8\")\n",
    "l = Compressor()\n",
    "l.use_lzma()\n",
    "compr_lzma = l.compress(binary_data)\n",
    "l.decompress(compr_lzma) # let's validate it actually works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09b78f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xfd7zXZ\\x00\\x00\\x04\\xe6\\xd6\\xb4F\\x02\\x00!\\x01\\x16\\x00\\x00\\x00t/\\xe5\\xa3\\xe0\\x010\\x00\\xd1]\\x00$\\x88\\t\\xa7S\\xc9\\xf0\\xedW\\x8fZ\\'\\xd9A\\xbb\\xa72\\xfe\\x89\\xe2\\x00.|\\x86\\xc6\\x00\\x8c\\xd3\\xcaG\\xc3\\xf9\\xde\\xcc.Mz\\xef\\x13\\x88\\n\\xea\\xc2%\\xd3\\x1f3Vc \\x1c\\xe0\\xe8V\\x8fG\\x0e\\xb5\\xd6\\x120\\xf9\\xcei\\x88\\xf6\\x0e[\\xe8\\x1f\\x02]x?\\x08G\\xb5\\r#\\xd3\\x02\\xb1\\xa6\\xdf\\x18k\\xb12nKkT?\\x83 \\xac\\xecy\\xee\\xe5\\xb0\\xc3s\\xf1*u\\xda2\\x8cJl9\\x04$\\xce\\x06\\xde\\xa2\\xb6U\\xaa\\xe6\\xa9\"w?\\xdb!J\\xd1\\x92y\\xb4\\xc7\\x00\\x8dL\\xf0\\x94\\xe6\\xa5tv\"\\x145\\x1b\\x9a\\xcf\\xf1\\xefR\\x95Bf3Q\\x1b,&xlH\\xe5Q\\n\\xf2\\xca\\x9d\\xac-\\x1d\\xb1v\\'R\\x1e\\xf9}\\x0f\\xfeZj\\n,t\\xbc\\xa9o;u\\xf2+\\xa6\\xe8\\xe7\\x10\\x97\\x84-gd]\\xfe\\xec\\x94\\xf1/\\x00\\x00\\x00\\x00\\x00\\xb6\\xa9\\x1a\\x86)\\x08\\xd1a\\x00\\x01\\xed\\x01\\xb1\\x02\\x00\\x00\\xa0\\x08\\xa5\\xf2\\xb1\\xc4g\\xfb\\x02\\x00\\x00\\x00\\x00\\x04YZ'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compr_lzma # this is the encoded string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65165ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9049180327868852\n"
     ]
    }
   ],
   "source": [
    "print(len(compr_lzma)*8 / (len(test_string)*8)) # 2208 bits / 2240 bits\n",
    "# in this scenario, Huffman is better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "433098bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'I must not fear. Fear is the mind-killer. Fear is the little-death that brings total obliteration. I will face my fear. I will permit it to pass over me and through me. And when it has gone past, I will turn the inner eye to see its path. Where the fear has gone there will be nothing. Only I will remain.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare with GZIP\n",
    "g = Compressor()\n",
    "g.use_gzip()\n",
    "compr_gzip = g.compress(binary_data)\n",
    "g.decompress(compr_gzip) # let's validate it actually works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee0d22ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6655737704918033\n"
     ]
    }
   ],
   "source": [
    "print(len(compr_gzip)*8 / (len(test_string)*8)) # 1624 bits / 2240 bits\n",
    "# in this scenario, Huffman is better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f938e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2440 bits compressed to 2208 bits, ratio 0.905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9049180327868852"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another implementation of the lzma algorithm, from library lzma\n",
    "def lzma_compression_ratio(test_string):\n",
    "    bytes_in = bytes(test_string, 'utf-8')\n",
    "    bytes_out = lzma.compress(bytes_in)\n",
    "    lbi = len(bytes_in) * 8 # simply alteration so that the code returns bits, not bytes\n",
    "    lbo = len(bytes_out) * 8\n",
    "    ratio = lbo / lbi\n",
    "    message = '%d bits compressed to %d bits, ratio %0.3f'%(lbi, lbo, ratio)\n",
    "    print(message)\n",
    "    return ratio\n",
    "\n",
    "lzma_compression_ratio(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3398a879",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol   Code            Frequency \n",
      "a        011             200       \n",
      "c        010             200       \n",
      "e        001             200       \n",
      "f        111             100       \n",
      "x        110             100       \n",
      "y        101             100       \n",
      "z        100             100       \n",
      "b        0001            100       \n",
      "d        0000            100       \n",
      "Compressed size vs. original (bits):  40% ,  3800 / 9600  bits\n",
      "Encoded \n",
      " 01100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111011000101000000011110110001010000000111101100010100000001111110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001110101100011010001\n",
      "Decoded \n",
      " abcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefxyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzacexyzace\n"
     ]
    }
   ],
   "source": [
    "# let's try a text with a lot of repetitions\n",
    "new_test = \"abcdef\" * 100 + \"xyzace\" * 100\n",
    "encoding, tree = Encode(new_test)\n",
    "print(\"Encoded \\n\", encoding)\n",
    "print(\"Decoded \\n\", Decode(encoding, tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfe351da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07666666666666666\n"
     ]
    }
   ],
   "source": [
    "compr_lzma_new = l.compress((new_test).encode(\"utf-8\"))\n",
    "l.decompress(compr_lzma_new)\n",
    "print(len(compr_lzma_new)*8 / (len(new_test)*8)) # 736 bits / 9600 bits, much better than Huffman's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d657d509",
   "metadata": {},
   "source": [
    "### Sources\n",
    "\n",
    "- [Data compression, Wikipedia](https://en.wikipedia.org/wiki/Data_compression)\n",
    "- [Lossy compression, Wikipedia](https://en.wikipedia.org/wiki/Lossy_compression)\n",
    "- [Lossless compression, Wikipedia](https://en.wikipedia.org/wiki/Lossless_compression)\n",
    "- [Entropy (Information theory), Wikipedia](https://en.wikipedia.org/wiki/Entropy_(information_theory))\n",
    "- [Huffman Coding, Wikipedia](https://en.wikipedia.org/wiki/Huffman_coding)\n",
    "- Images from [Huffman Coding, progamiz.com](https://www.programiz.com/dsa/huffman-coding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
